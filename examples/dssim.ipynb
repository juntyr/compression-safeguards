{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b1a34-e6e4-4164-9d60-b21e55c016b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_stdlib_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe357e-8cf0-47be-a89b-4d9d0a49ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import earthkit.plots\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from astropy.convolution import Gaussian2DKernel, convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054771a-d8f6-4a1b-b452-698aa342e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data\n",
    "ERA5 = xr.open_dataset(Path() / \"data\" / \"era5-uv\" / \"data.nc\")\n",
    "ERA5_U = ERA5[\"u\"].sel(valid_time=\"2024-04-02T12:00:00\", pressure_level=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf0425-7ece-4e1f-9f09-b84dcd283520",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46081222-815b-4f04-9d22-f43946c6bac8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def plot_data(\n",
    "    da: xr.DataArray,\n",
    "    title_prefix=\"\",\n",
    "    title_postfix=\"\",\n",
    "    error=False,\n",
    "    n_levels=256,\n",
    "    cmap=None,\n",
    "    divergence_point=None,\n",
    "    levels=None,\n",
    "    chart=None,\n",
    "    **kwargs,\n",
    "):\n",
    "    UNITS = dict(t2m=\"degC\")\n",
    "    DIVERGENCE_POINT = dict(t2m=0.0)\n",
    "\n",
    "    units = None if error else UNITS.get(da.name, None)\n",
    "    divergence_point = (\n",
    "        divergence_point\n",
    "        if divergence_point is not None\n",
    "        else 0.0\n",
    "        if error\n",
    "        else DIVERGENCE_POINT.get(da.name, None)\n",
    "    )\n",
    "\n",
    "    source = earthkit.plots.sources.XarraySource(da)\n",
    "\n",
    "    # compute the default style that earthkit.maps would apply\n",
    "    style = copy.deepcopy(\n",
    "        earthkit.plots.styles.auto.guess_style(\n",
    "            source,\n",
    "            units=units or source.units,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    da_units = style.convert_units(da.values, source.units)\n",
    "\n",
    "    # modify the style levels to get a smoother colourbar\n",
    "    style._levels = earthkit.plots.styles.levels.Levels(\n",
    "        levels\n",
    "        if levels is not None\n",
    "        else earthkit.plots.styles.levels.auto_range(\n",
    "            da_units,\n",
    "            divergence_point=divergence_point,\n",
    "            n_levels=n_levels,\n",
    "        )\n",
    "    )\n",
    "    style._legend_kwargs[\"ticks\"] = earthkit.plots.styles.levels.auto_range(\n",
    "        da_units,\n",
    "        divergence_point=divergence_point,\n",
    "        n_levels=10,\n",
    "    )\n",
    "\n",
    "    style._kwargs.update(kwargs)\n",
    "\n",
    "    # force the colourmap to coolwarm for error plots\n",
    "    style._colors = cmap if cmap is not None else \"coolwarm\" if error else style._colors\n",
    "\n",
    "    show = chart is None\n",
    "    if chart is None:\n",
    "        chart = earthkit.plots.Map()\n",
    "\n",
    "    # quickplot with the modified style\n",
    "    chart.quickplot(\n",
    "        da,\n",
    "        units=units,\n",
    "        style=style,\n",
    "    )\n",
    "\n",
    "    for m in earthkit.plots.schemas.schema.quickmap_subplot_workflow:\n",
    "        if m != \"title\":\n",
    "            getattr(chart, m)()\n",
    "\n",
    "    for m in earthkit.plots.schemas.schema.quickmap_figure_workflow:\n",
    "        getattr(chart, m)()\n",
    "\n",
    "    chart.title(\n",
    "        f\"{title_prefix}{{variable_name}} on {{time:%d.%m.%Y at %H:%M}}{title_postfix}\"\n",
    "    )\n",
    "\n",
    "    if show:\n",
    "        chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4d717-40f6-455d-b65c-55a5b834f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(ERA5_U, title_prefix=\"Original \", divergence_point=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f46815-7860-4940-830b-caa3e3865c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dssim(\n",
    "    a1: np.ndarray,\n",
    "    a2: np.ndarray,\n",
    "    eps: float = 1e-8,\n",
    "    kernel_size: int = 11,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Implementation adapted from the official dSSIM implementation at\n",
    "    https://github.com/NCAR/ldcpy/blob/6c5bcb8149ec7876a4f53b0e784e9c528f6f14cb/ldcpy/calcs.py#L2516\n",
    "\n",
    "    The official implementation makes assumptions about the input data that are\n",
    "    specific to models developed at NCAR which is why we cannot use the official\n",
    "    implementation directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Shape: (latitude, longitude)\n",
    "    y : np.ndarray\n",
    "        Shape: (latitude, longitude)\n",
    "    kernel_size : int\n",
    "        The size of the Gaussian kernel for the convolution operation in SSIM. Has to be\n",
    "        an odd number. The default is 11.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The data-SSIM value between the two input arrays.\n",
    "    \"\"\"\n",
    "    assert kernel_size % 2 == 1, \"kernel_size must be an odd number.\"\n",
    "\n",
    "    # re-scale  to [0,1] - if not constant\n",
    "    smin = min(np.nanmin(a1), np.nanmin(a2))\n",
    "    smax = max(np.nanmax(a1), np.nanmax(a2))\n",
    "    r = smax - smin\n",
    "    if r == 0.0:  # scale by smax if field is a constant (and smax != 0)\n",
    "        if smax == 0.0:\n",
    "            sc_a1 = a1\n",
    "            sc_a2 = a2\n",
    "        else:\n",
    "            sc_a1 = a1 / smax\n",
    "            sc_a2 = a2 / smax\n",
    "    else:\n",
    "        sc_a1 = (a1 - smin) / r\n",
    "        sc_a2 = (a2 - smin) / r\n",
    "\n",
    "    # now quantize to 256 bins\n",
    "    sc_a1 = np.round(sc_a1 * 255) / 255\n",
    "    sc_a2 = np.round(sc_a2 * 255) / 255\n",
    "\n",
    "    # gaussian filter\n",
    "    kernel = Gaussian2DKernel(x_stddev=1.5, x_size=kernel_size, y_size=kernel_size)\n",
    "    filter_args = {\"boundary\": \"fill\", \"preserve_nan\": True}\n",
    "\n",
    "    a1_mu = convolve(sc_a1, kernel, **filter_args)\n",
    "    a2_mu = convolve(sc_a2, kernel, **filter_args)\n",
    "\n",
    "    a1a1 = convolve(sc_a1 * sc_a1, kernel, **filter_args)\n",
    "    a2a2 = convolve(sc_a2 * sc_a2, kernel, **filter_args)\n",
    "\n",
    "    a1a2 = convolve(sc_a1 * sc_a2, kernel, **filter_args)\n",
    "\n",
    "    ###########\n",
    "    var_a1 = a1a1 - a1_mu * a1_mu\n",
    "    var_a2 = a2a2 - a2_mu * a2_mu\n",
    "    cov_a1a2 = a1a2 - a1_mu * a2_mu\n",
    "\n",
    "    # ssim constants\n",
    "    C1 = eps\n",
    "    C2 = eps\n",
    "\n",
    "    ssim_t1 = 2 * a1_mu * a2_mu + C1\n",
    "    ssim_t2 = 2 * cov_a1a2 + C2\n",
    "\n",
    "    ssim_b1 = a1_mu * a1_mu + a2_mu * a2_mu + C1\n",
    "    ssim_b2 = var_a1 + var_a2 + C2\n",
    "\n",
    "    ssim_1 = ssim_t1 / ssim_b1\n",
    "    ssim_2 = ssim_t2 / ssim_b2\n",
    "    ssim_mat = ssim_1 * ssim_2\n",
    "\n",
    "    # Cropping the border region of the 2D field where the convolution kernel is not\n",
    "    # fully overlapping with the 2D input field.\n",
    "    k = (kernel_size - 1) // 2\n",
    "    ssim_mat = ssim_mat[k : ssim_mat.shape[0] - k, k : ssim_mat.shape[1] - k]\n",
    "    return np.nanmean(ssim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38be4c-6010-4831-9793-b9bf11594417",
   "metadata": {},
   "outputs": [],
   "source": [
    "dssim(ERA5_U.values, ERA5_U.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f3e1dd-c673-472c-a481-0a7792322918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numcodecs_wasm_zfp import Zfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb3244-2314-4880-9b22-f2e1fda0a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zfp = Zfp(mode=\"fixed-accuracy\", tolerance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80922f2d-6bbc-445f-ad9e-77da2413431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_U_zfp = ERA5_U.copy(data=zfp.decode(zfp.encode(ERA5_U.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65511cea-dc74-4301-8bce-e6f03163a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(np.abs(ERA5_U - ERA5_U_zfp)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac44250c-ce7d-40a5-bff2-0c293493d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "dssim(ERA5_U.values, ERA5_U_zfp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67780705-a175-403b-b97b-2796fa7f8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression_safeguards import Safeguards\n",
    "from compression_safeguards.utils.bindings import Bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e791d72d-a0cb-4acb-847e-ae3fcc566b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.zeros_like(ERA5_U.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804bf66-e8c2-4c76-a9e0-f30b3343d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baker et al. (2023) On a Structural Similarity Index Approach for Floating-Point Data\n",
    "for dssim_bound in [0.99, 0.995, 0.99919]:\n",
    "    sg = Safeguards(\n",
    "        safeguards=[\n",
    "            dict(kind=\"sign\", offset=\"$x_min\"),\n",
    "            dict(kind=\"sign\", offset=\"$x_max\"),\n",
    "            dict(\n",
    "                kind=\"qoi_eb_stencil\",\n",
    "                qoi=\"\"\"\n",
    "                let(\n",
    "                    # we guarantee that\n",
    "                    #  min(data) = min(corrected) and\n",
    "                    #  max(data) = max(corrected)\n",
    "                    # with the sign safeguards above\n",
    "                    V[\"smin\"], c[\"$x_min\"],\n",
    "                    V[\"smax\"], c[\"$x_max\"],\n",
    "                )(let(\n",
    "                    V[\"r\"], V[\"smax\"] - V[\"smin\"],\n",
    "                )\n",
    "                \n",
    "                (let(\n",
    "                    # re-scale to [0-1] and quantize to 256 bins\n",
    "                    V[\"sc_a1\"], round_ties_even((C[\"$X\"] - V[\"smin\"]) / V[\"r\"] * 255) / 255,\n",
    "                    V[\"sc_a2\"], round_ties_even((X - V[\"smin\"]) / V[\"r\"] * 255) / 255,\n",
    "                )\n",
    "    \n",
    "                (let(\n",
    "                    # create a 2D 11x11 Gaussian kernel\n",
    "                    V[\"i\"], A[-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5],\n",
    "                )(let(\n",
    "                    V[\"k\"], 1/(sqrt(2*pi)*c[\"sigma\"]) * exp((-V[\"i\"]**2) / (2*c[\"sigma\"]**2)),\n",
    "                )(let(\n",
    "                    V[\"k_norm\"], V[\"k\"] / asum(V[\"k\"]),\n",
    "                )(let(\n",
    "                    V[\"kernel\"], matmul(tr(A[V[\"k_norm\"]]), A[V[\"k_norm\"]]),\n",
    "                )\n",
    "    \n",
    "                (let(\n",
    "                    # apply the Gaussian filter\n",
    "                    V[\"a1_mu\"], matmul(V[\"sc_a1\"], V[\"kernel\"])[0,0],\n",
    "                    V[\"a2_mu\"], matmul(V[\"sc_a2\"], V[\"kernel\"])[0,0],\n",
    "                    V[\"a1a1\"], matmul(V[\"sc_a1\"]**2, V[\"kernel\"])[0,0],\n",
    "                    V[\"a2a2\"], matmul(V[\"sc_a2\"]**2, V[\"kernel\"])[0,0],\n",
    "                    V[\"a1a2\"], matmul(V[\"sc_a1\"] * V[\"sc_a2\"], V[\"kernel\"])[0,0],\n",
    "                )\n",
    "    \n",
    "                (let(\n",
    "                    ###########\n",
    "                    V[\"var_a1\"], V[\"a1a1\"] - V[\"a1_mu\"]**2,\n",
    "                    V[\"var_a2\"], V[\"a2a2\"] - V[\"a2_mu\"]**2,\n",
    "                    V[\"cov_a1a2\"], V[\"a1a2\"] - V[\"a1_mu\"] * V[\"a2_mu\"],\n",
    "                )\n",
    "    \n",
    "                (let(\n",
    "                    # compute the SSIM components\n",
    "                    V[\"ssim_t1\"], 2 * V[\"a1_mu\"] * V[\"a2_mu\"] + c[\"C1\"],\n",
    "                    V[\"ssim_t2\"], 2 * V[\"cov_a1a2\"] + c[\"C2\"],\n",
    "                    V[\"ssim_b1\"], V[\"a1_mu\"]**2 + V[\"a2_mu\"]**2 + c[\"C1\"],\n",
    "                    V[\"ssim_b2\"], V[\"var_a1\"] + V[\"var_a2\"] + c[\"C2\"],\n",
    "                )\n",
    "    \n",
    "                (let(\n",
    "                    V[\"ssim_1\"], V[\"ssim_t1\"] / V[\"ssim_b1\"],\n",
    "                    V[\"ssim_2\"], V[\"ssim_t2\"] / V[\"ssim_b2\"],\n",
    "                )\n",
    "                \n",
    "                (\n",
    "                    # compute the pointwise dSSIM\n",
    "                    V[\"ssim_1\"] * V[\"ssim_2\"]\n",
    "                )))))))))))\n",
    "                \"\"\",\n",
    "                type=\"abs\",\n",
    "                eb=1 - dssim_bound,\n",
    "                # 11x11 neighbourhood\n",
    "                neighbourhood=[\n",
    "                    # latitude\n",
    "                    dict(axis=0, before=5, after=5, boundary=\"valid\"),\n",
    "                    # longitude\n",
    "                    dict(axis=1, before=5, after=5, boundary=\"valid\"),\n",
    "                ],\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    correction_sg = sg.compute_correction(\n",
    "        ERA5_U.values,\n",
    "        prediction,\n",
    "        late_bound=Bindings(\n",
    "            **{\n",
    "                \"$x_min\": np.nanmin(ERA5_U),\n",
    "                \"$x_max\": np.nanmax(ERA5_U),\n",
    "            },\n",
    "            sigma=np.array(1.5, dtype=ERA5_U.dtype)[()],\n",
    "            C1=np.array(1e-8, dtype=ERA5_U.dtype)[()],\n",
    "            C2=np.array(1e-8, dtype=ERA5_U.dtype)[()],\n",
    "        ),\n",
    "    )\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    ERA5_U_sg = ERA5_U.copy(data=sg.apply_correction(prediction, correction_sg))\n",
    "\n",
    "    print(\n",
    "        f\"dSSIM >= {dssim_bound}: abs={np.amax(np.abs(ERA5_U - ERA5_U_sg)).item()} dSSIM={dssim(ERA5_U.values, ERA5_U_sg.values)} time={end - start}s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966aeb25-b2cd-4e9b-9db3-a5a3ff6d1cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sg.safeguards[0]._qoi_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f15d6-5b12-433f-b01f-eb4f130b6dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
