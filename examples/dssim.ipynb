{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e6663b-9c10-433c-b6a9-21115d206ccf",
   "metadata": {},
   "source": [
    "# Preserving the structural similarity index for floating-point data (dSSIM) with safeguards\n",
    "\n",
    "In this example, we compare the structural similarity index for floating-point data (dSSIM) [^1] after compressing a dataset of `u` wind with three different lossy compressors (ZFP, SZ3, SPERR). We then stress-test the quantity of interest (QoI) implementation of the safeguards by preserving an error bound on the dSSIM by translating the dSSIM computation into a quantity of interest, which involves rescaling and linearly quantizing values, applying a 2D Gaussian smoothing kernel, and computing variances and co-variances.\n",
    "\n",
    "[^1]: Baker, A. H., Pinard, A. and Hammerling, D. M. (2024). On a Structural Similarity Index Approach for Floating-Point Data. *IEEE Transactions on Visualization and Computer Graphics*. 30(9), 6261-6274. Available from: [doi:10.1109/TVCG.2023.3332843](https://doi.org/10.1109/TVCG.2023.3332843)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b1a34-e6e4-4164-9d60-b21e55c016b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_stdlib_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe357e-8cf0-47be-a89b-4d9d0a49ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import earthkit.plots\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054771a-d8f6-4a1b-b452-698aa342e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data\n",
    "ERA5 = xr.open_dataset(Path() / \"data\" / \"era5-uv\" / \"data.nc\")\n",
    "ERA5_U = (\n",
    "    ERA5[\"u\"]\n",
    "    .sel(valid_time=\"2024-04-02T12:00:00\", pressure_level=500)\n",
    "    .astype(np.float64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf0425-7ece-4e1f-9f09-b84dcd283520",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f46815-7860-4940-830b-caa3e3865c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dssim_mat(\n",
    "    a1: np.ndarray,\n",
    "    a2: np.ndarray,\n",
    "    eps: float = 1e-8,\n",
    "    kernel_size: int = 3,\n",
    "    reproducible: bool = True,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implementation adapted from the official dSSIM implementation at\n",
    "    https://github.com/NCAR/ldcpy/blob/6c5bcb8149ec7876a4f53b0e784e9c528f6f14cb/ldcpy/calcs.py#L2516\n",
    "\n",
    "    The official implementation makes assumptions about the input data that are\n",
    "    specific to models developed at NCAR which is why we cannot use the official\n",
    "    implementation directly.\n",
    "\n",
    "    The implementation has been further adapted to ensure bit-reproducible\n",
    "    evaluation with the below dSSIM quantity of interest, with the following\n",
    "    notable changes:\n",
    "\n",
    "    - we take extra care to ensure all operations are computed in the data\n",
    "      dtype, i.e. without accidentally upcasting to np.float64\n",
    "    - the original uses np.round, which rounds halfway cases away from zero,\n",
    "      we use np.rint which rounds halfway cases to the nearest even integer\n",
    "    - the original uses astropy.convolution.convolve, which internally upcasts\n",
    "      to float64 - to avoid rounding differences, we manually implement it here\n",
    "    - astropy.convolution.convolve handles NaN values by replacing them during\n",
    "      convolution with a Gaussian kernel by interpolating with the same\n",
    "      Gaussian kernel, to avoid NaNs bleeding over, and by returning NaN for\n",
    "      elements that were NaN in the input. We implement a simpler version by\n",
    "      excluding NaN values from the convolution and returning NaN for elements\n",
    "      that were NaN in the input\n",
    "    - convolution requires summation but np.sum internally uses partial sums\n",
    "      for better rounding, which the safeguards currently do not use, so we\n",
    "      manually sum\n",
    "    - we reduce the 11x11 Gaussian kernel to 3x3 for the sake of compute time\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Shape: (latitude, longitude)\n",
    "    y : np.ndarray\n",
    "        Shape: (latitude, longitude)\n",
    "    kernel_size : int\n",
    "        The size of the Gaussian kernel for the convolution operation in SSIM. Has to be\n",
    "        an odd number. The default is 3.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dssim : np.ndarray\n",
    "        The pointwise data-SSIM values where the k x k kernel is valid.\n",
    "    \"\"\"\n",
    "    assert kernel_size % 2 == 1, \"kernel_size must be an odd number.\"\n",
    "    assert a1.shape == a2.shape\n",
    "    assert a1.dtype == a2.dtype\n",
    "\n",
    "    # re-scale  to [0,1] - if not constant\n",
    "    smin = min(np.nanmin(a1), np.nanmin(a2))\n",
    "    smax = max(np.nanmax(a1), np.nanmax(a2))\n",
    "    r = smax - smin\n",
    "    if r == 0:  # scale by smax if field is a constant (and smax != 0)\n",
    "        if smax == 0:\n",
    "            sc_a1 = a1\n",
    "            sc_a2 = a2\n",
    "        else:\n",
    "            sc_a1 = a1 / smax\n",
    "            sc_a2 = a2 / smax\n",
    "    else:\n",
    "        sc_a1 = (a1 - smin) / r\n",
    "        sc_a2 = (a2 - smin) / r\n",
    "\n",
    "    # now quantize to 256 bins\n",
    "    sc_a1 = np.rint(sc_a1 * 255) / 255\n",
    "    sc_a2 = np.rint(sc_a2 * 255) / 255\n",
    "\n",
    "    # 2D gaussian filter\n",
    "    sigma = a1.dtype.type(1.5)\n",
    "    pi = a1.dtype.type(np.pi)\n",
    "\n",
    "    i = np.arange(kernel_size).astype(a1.dtype) - (kernel_size // 2)\n",
    "    k = 1 / (np.sqrt(2 * pi) * sigma) * np.exp((-np.square(i)) / (2 * np.square(sigma)))\n",
    "    kernel = np.array([k]).T @ np.array([k])\n",
    "\n",
    "    def convolve(a, k):\n",
    "        # pad with zeros\n",
    "        ap = np.pad(a, kernel_size // 2, mode=\"constant\", constant_values=0)\n",
    "        # reshape a to (*a.shape, *k.shape)\n",
    "        av = np.lib.stride_tricks.as_strided(\n",
    "            ap, a.shape + k.shape, ap.strides + ap.strides\n",
    "        )\n",
    "\n",
    "        # broadcast k to (*a.shape, *k.shape)\n",
    "        kv = np.copy(\n",
    "            np.broadcast_to(k.reshape((1, 1, kernel_size, kernel_size)), av.shape)\n",
    "        )\n",
    "\n",
    "        # exclude weights in kv where av is NaN\n",
    "        kv[np.isnan(av)] = 0\n",
    "        # renormalize kv\n",
    "        kv_flat = kv.reshape(a.shape + (-1,))\n",
    "        if reproducible:\n",
    "            # manual np.sum over the last dimension\n",
    "            kv_acc = np.copy(kv_flat[..., 0])\n",
    "            for i in range(1, kv_flat.shape[-1]):\n",
    "                kv_acc += kv_flat[..., i]\n",
    "        else:\n",
    "            kv_acc = np.sum(kv_flat, axis=-1)\n",
    "        kv /= kv_acc.reshape(a.shape + (1, 1))\n",
    "\n",
    "        # pointwise multiply av with kv, then reshape to (*a.shape, -1)\n",
    "        ag = (av * kv).reshape(a.shape + (-1,))\n",
    "        if reproducible:\n",
    "            # manual np.sum over the last dimension\n",
    "            acc = np.copy(ag[..., 0])\n",
    "            for i in range(1, ag.shape[-1]):\n",
    "                acc += ag[..., i]\n",
    "        else:\n",
    "            acc = np.sum(ag, axis=-1)\n",
    "\n",
    "        # keep NaN for elements that are NaN in a\n",
    "        return np.where(np.isnan(a), np.nan, acc)\n",
    "\n",
    "    a1_mu = convolve(sc_a1, kernel)\n",
    "    a2_mu = convolve(sc_a2, kernel)\n",
    "\n",
    "    a1a1 = convolve(np.square(sc_a1), kernel)\n",
    "    a2a2 = convolve(np.square(sc_a2), kernel)\n",
    "\n",
    "    a1a2 = convolve(sc_a1 * sc_a2, kernel)\n",
    "\n",
    "    ###########\n",
    "    var_a1 = a1a1 - np.square(a1_mu)\n",
    "    var_a2 = a2a2 - np.square(a2_mu)\n",
    "    cov_a1a2 = a1a2 - a1_mu * a2_mu\n",
    "\n",
    "    # ssim constants\n",
    "    C1 = a1.dtype.type(eps)\n",
    "    C2 = a1.dtype.type(eps)\n",
    "\n",
    "    ssim_t1 = 2 * a1_mu * a2_mu + C1\n",
    "    ssim_t2 = 2 * cov_a1a2 + C2\n",
    "\n",
    "    ssim_b1 = np.square(a1_mu) + np.square(a2_mu) + C1\n",
    "    ssim_b2 = var_a1 + var_a2 + C2\n",
    "\n",
    "    ssim_1 = ssim_t1 / ssim_b1\n",
    "    ssim_2 = ssim_t2 / ssim_b2\n",
    "    ssim_mat = ssim_1 * ssim_2\n",
    "\n",
    "    # Cropping the border region of the 2D field where the convolution kernel is not\n",
    "    # fully overlapping with the 2D input field.\n",
    "    k = (kernel_size - 1) // 2\n",
    "    return ssim_mat[k : ssim_mat.shape[0] - k, k : ssim_mat.shape[1] - k]\n",
    "\n",
    "\n",
    "def dssim(\n",
    "    a1: np.ndarray,\n",
    "    a2: np.ndarray,\n",
    "    eps: float = 1e-8,\n",
    "    kernel_size: int = 3,\n",
    "    reproducible: bool = True,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Implementation adapted from the official dSSIM implementation at\n",
    "    https://github.com/NCAR/ldcpy/blob/6c5bcb8149ec7876a4f53b0e784e9c528f6f14cb/ldcpy/calcs.py#L2516\n",
    "\n",
    "    The official implementation makes assumptions about the input data that are\n",
    "    specific to models developed at NCAR which is why we cannot use the official\n",
    "    implementation directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Shape: (latitude, longitude)\n",
    "    y : np.ndarray\n",
    "        Shape: (latitude, longitude)\n",
    "    kernel_size : int\n",
    "        The size of the Gaussian kernel for the convolution operation in SSIM. Has to be\n",
    "        an odd number. The default is 3.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dssim : float\n",
    "        The data-SSIM value between the two input arrays.\n",
    "    \"\"\"\n",
    "    return np.nanmean(\n",
    "        dssim_mat(a1, a2, eps=eps, kernel_size=kernel_size, reproducible=reproducible)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38be4c-6010-4831-9793-b9bf11594417",
   "metadata": {},
   "outputs": [],
   "source": [
    "dssim(ERA5_U.values, ERA5_U.values, reproducible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ae41e-67fd-4fc0-b114-903d29d722a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cmap_and_norm = earthkit.plots.styles.colors.cmap_and_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adb5580-dd90-4350-81db-4b1740775b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cmap_and_norm(colors, levels, normalize=True, extend=None, extend_levels=True):\n",
    "    return old_cmap_and_norm(colors, levels, normalize, extend, True)\n",
    "\n",
    "\n",
    "earthkit.plots.styles.colors.cmap_and_norm = my_cmap_and_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c309b6-f858-4351-a4c2-8e3c5bc8f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_u_wind_dssim(\n",
    "    my_ERA5_U: xr.DataArray,\n",
    "    cr,\n",
    "    chart,\n",
    "    title,\n",
    "    span,\n",
    "    error=False,\n",
    "):\n",
    "    import copy\n",
    "\n",
    "    if error:\n",
    "        err_U = np.amax(np.abs(my_ERA5_U - ERA5_U))\n",
    "\n",
    "        with xr.set_options(keep_attrs=True):\n",
    "            da = ERA5_U[1:-1, 1:-1].copy(\n",
    "                data=dssim_mat(\n",
    "                    ERA5_U.values,\n",
    "                    my_ERA5_U.values,\n",
    "                    reproducible=False,\n",
    "                )\n",
    "            )\n",
    "            da.attrs.update(long_name=f\"dSSIM({da.long_name})\", units=None)\n",
    "\n",
    "        dssim_mean = np.nanmean(da)\n",
    "        dssim_min = np.nanmin(da)\n",
    "        dssim_max = np.nanmax(da)\n",
    "    else:\n",
    "        da = my_ERA5_U\n",
    "\n",
    "    # compute the default style that earthkit.maps would apply\n",
    "    source = earthkit.plots.sources.XarraySource(da)\n",
    "    style = copy.deepcopy(\n",
    "        earthkit.plots.styles.auto.guess_style(\n",
    "            source,\n",
    "            units=source.units,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    style._levels = earthkit.plots.styles.levels.Levels(np.linspace(*span, 22))\n",
    "    style._legend_kwargs[\"ticks\"] = np.linspace(*span, 5)\n",
    "\n",
    "    if error:\n",
    "        style._colors = \"cool_r\"\n",
    "\n",
    "    extend_left = np.nanmin(da) < span[0]\n",
    "    extend_right = np.nanmax(da) > span[1]\n",
    "\n",
    "    extend = {\n",
    "        (False, False): \"neither\",\n",
    "        (True, False): \"min\",\n",
    "        (False, True): \"max\",\n",
    "        (True, True): \"both\",\n",
    "    }[(extend_left, extend_right)]\n",
    "\n",
    "    if error:\n",
    "        style._legend_kwargs[\"extend\"] = extend\n",
    "        chart.pcolormesh(da, style=style, zorder=-11)\n",
    "    else:\n",
    "        chart.quickplot(da, style=style, extend=extend, zorder=-11)\n",
    "\n",
    "    chart.ax.set_rasterization_zorder(-10)\n",
    "\n",
    "    if error:\n",
    "        chart.title(\n",
    "            f\"{title}\\n\"\n",
    "            + rf\"$L_{{{{\\infty}}}}(\\hat{{{{u}}}})$={err_U:.03}  $dSSIM(u, \\hat{{{{u}}}})$={dssim_mean:.05} ({dssim_min:.03} $\\leq$ $dSSIM$ $\\leq$ {dssim_max:.03})\"\n",
    "        )\n",
    "    else:\n",
    "        chart.title(f\"{title}\\n\")\n",
    "\n",
    "    if error:\n",
    "        t = chart.ax.text(\n",
    "            0.95,\n",
    "            0.9,\n",
    "            f\"x {np.round(cr, 2)}\",\n",
    "            ha=\"right\",\n",
    "            va=\"top\",\n",
    "            transform=chart.ax.transAxes,\n",
    "        )\n",
    "        t.set_bbox(dict(facecolor=\"white\", alpha=0.75, edgecolor=\"black\"))\n",
    "\n",
    "    for m in earthkit.plots.schemas.schema.quickmap_subplot_workflow:\n",
    "        if m != \"title\":\n",
    "            getattr(chart, m)()\n",
    "\n",
    "    for m in earthkit.plots.schemas.schema.quickmap_figure_workflow:\n",
    "        getattr(chart, m)()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9bb981-85ed-46f2-891d-ec79a0a5b27d",
   "metadata": {},
   "source": [
    "## Compressing u with lossy compressors\n",
    "\n",
    "We compare each compressor with two absolute error bounds, 1 m/s and 0.1 m/s, to compare the dSSIM scores they achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13e062-22a1-4228-aac6-30a444520372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numcodecs_wasm_sperr import Sperr\n",
    "from numcodecs_wasm_sz3 import Sz3\n",
    "from numcodecs_wasm_zfp import Zfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d78f0-8afb-4403-8f53-68387bef86b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_abs = [1.0, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6bb4f-7cfa-4ef0-b68a-c4b1af76aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_U_codec = defaultdict(dict)\n",
    "ERA5_U_codec_cr = defaultdict(dict)\n",
    "\n",
    "for ea in eb_abs:\n",
    "    for codec in [\n",
    "        Zfp(mode=\"fixed-accuracy\", tolerance=ea),\n",
    "        Sz3(eb_mode=\"abs\", eb_abs=ea),\n",
    "        Sperr(mode=\"pwe\", pwe=ea),\n",
    "    ]:\n",
    "        ERA5_U_codec_enc = codec.encode(ERA5_U.values)\n",
    "        ERA5_U_codec[codec.codec_id][ea] = ERA5_U.copy(\n",
    "            data=codec.decode(ERA5_U_codec_enc)\n",
    "        )\n",
    "        ERA5_U_codec_cr[codec.codec_id][ea] = ERA5_U.nbytes / ERA5_U_codec_enc.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63bbb84-bc41-4564-a522-2bdab376f6c0",
   "metadata": {},
   "source": [
    "## Compressing u using the safeguards-wrapped lossy compressors\n",
    "\n",
    "We configure the safeguards to bound the dSSIM to be $\\geq 0.995$ using a spatial quantity of interest (QoI). In the translation of the dSSIM calculation to a QoI, we make use of the following tricks:\n",
    "\n",
    "- we preserve the global minimum and maximum exactly, using sign safeguards with offsets, to ensure that the linear quantisation range is constant\n",
    "- we manually create a 2D Gaussian kernel in the QoI expression\n",
    "- we use valid boundary conditions to only compute the pointwise dSSIM for points that have a valid 3x3 neighbourhood\n",
    "- we compute the dSSIM of the (compressed) data with respect to the constant original data. When the QoI is evaluated on the original data, this computes $dSSIM(u, u) = 1$\n",
    "- we bound an absolute error of $\\epsilon_{abs} = 1 - 0.995$ on the QoI to ensure that $dSSIM(u, \\hat{u}) \\geq 0.995$\n",
    "- we conservatively bound the pointwise dSSIM, not the mean of the dSSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cfacb1-1639-4f3b-beef-b777f293827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression_safeguards import SafeguardKind\n",
    "\n",
    "dssim_bound = 0.995\n",
    "\n",
    "qoi_eb_stencil = SafeguardKind.qoi_eb_stencil.value(\n",
    "    qoi=\"\"\"\n",
    "    # dssim constants\n",
    "    V[\"sigma\"] = 1.5;\n",
    "    V[\"C1\"] = 1e-8;\n",
    "    V[\"C2\"] = 1e-8;\n",
    "    \n",
    "    # we guarantee that\n",
    "    #  min(data) = min(corrected) and\n",
    "    #  max(data) = max(corrected)\n",
    "    # with the sign safeguards above\n",
    "    V[\"smin\"] = c[\"$x_min\"];\n",
    "    V[\"smax\"] = c[\"$x_max\"];\n",
    "    V[\"r\"] = V[\"smax\"] - V[\"smin\"];\n",
    "    \n",
    "    # re-scale to [0-1] and quantize to 256 bins\n",
    "    # we use the identity function to enforce that its\n",
    "    #  argument is evaluated eagerly and not folded into\n",
    "    #  other terms - this results in consistent but slower\n",
    "    #  evaluation\n",
    "    V[\"sc_a1\"] = round_ties_even(((C[\"$X\"] - V[\"smin\"]) / V[\"r\"]) * 255) / 255;\n",
    "    V[\"sc_a2\"] = round_ties_even(((X - V[\"smin\"]) / V[\"r\"]) * 255) / 255;\n",
    "\n",
    "    # create a 2D 3x3 Gaussian kernel\n",
    "    V[\"i\"] = [-1, 0, 1];\n",
    "    V[\"k\"] = 1/(sqrt(2*pi)*V[\"sigma\"]) * exp((-square(V[\"i\"])) / (2*square(V[\"sigma\"])));\n",
    "    V[\"kern\"] = matmul([V[\"k\"]].T, [V[\"k\"]]);\n",
    "\n",
    "    # handle sparse NaN values by excluding them from the convolution,\n",
    "    # then renormalize the kernel\n",
    "    V[\"kern_no_NaN1\"] = where(isnan(V[\"sc_a1\"]), 0, V[\"kern\"]);\n",
    "    V[\"kernel1\"] = V[\"kern_no_NaN1\"] / sum(V[\"kern_no_NaN1\"]);\n",
    "    V[\"kern_no_NaN2\"] = where(isnan(V[\"sc_a2\"]), 0, V[\"kern\"]);\n",
    "    V[\"kernel2\"] = V[\"kern_no_NaN2\"] / sum(V[\"kern_no_NaN2\"]);\n",
    "    V[\"kern_no_NaN12\"] = where(isnan(V[\"sc_a1\"] * V[\"sc_a2\"]), 0, V[\"kern\"]);\n",
    "    V[\"kernel12\"] = V[\"kern_no_NaN12\"] / sum(V[\"kern_no_NaN12\"]);\n",
    "\n",
    "    # apply the Gaussian filter via convolution\n",
    "    V[\"a1_mu_noNaN\"] = sum(V[\"sc_a1\"] * V[\"kernel1\"]);\n",
    "    V[\"a2_mu_noNaN\"] = sum(V[\"sc_a2\"] * V[\"kernel2\"]);\n",
    "    V[\"a1a1_noNaN\"] = sum(square(V[\"sc_a1\"]) * V[\"kernel1\"]);\n",
    "    V[\"a2a2_noNaN\"] = sum(square(V[\"sc_a2\"]) * V[\"kernel2\"]);\n",
    "    V[\"a1a2_noNaN\"] = sum(V[\"sc_a1\"] * V[\"sc_a2\"] * V[\"kernel12\"]);\n",
    "\n",
    "    # keep NaN for elements that are originally NaN\n",
    "    V[\"a1_mu\"] = where(isnan(V[\"sc_a1\"])[I], NaN, V[\"a1_mu_noNaN\"]);\n",
    "    V[\"a2_mu\"] = where(isnan(V[\"sc_a2\"])[I], NaN, V[\"a2_mu_noNaN\"]);\n",
    "    V[\"a1a1\"] = where(isnan(V[\"sc_a1\"])[I], NaN, V[\"a1a1_noNaN\"]);\n",
    "    V[\"a2a2\"] = where(isnan(V[\"sc_a2\"])[I], NaN, V[\"a2a2_noNaN\"]);\n",
    "    V[\"a1a2\"] = where(isnan(V[\"sc_a1\"] * V[\"sc_a2\"])[I], NaN, V[\"a1a2_noNaN\"]);\n",
    "\n",
    "    ###########\n",
    "    V[\"var_a1\"] = V[\"a1a1\"] - square(V[\"a1_mu\"]);\n",
    "    V[\"var_a2\"] = V[\"a2a2\"] - square(V[\"a2_mu\"]);\n",
    "    V[\"cov_a1a2\"] = V[\"a1a2\"] - V[\"a1_mu\"] * V[\"a2_mu\"];\n",
    "    \n",
    "    # compute the SSIM components\n",
    "    V[\"ssim_t1\"] = 2 * V[\"a1_mu\"] * V[\"a2_mu\"] + V[\"C1\"];\n",
    "    V[\"ssim_t2\"] = 2 * V[\"cov_a1a2\"] + V[\"C2\"];\n",
    "    V[\"ssim_b1\"] = square(V[\"a1_mu\"]) + square(V[\"a2_mu\"]) + V[\"C1\"];\n",
    "    V[\"ssim_b2\"] = V[\"var_a1\"] + V[\"var_a2\"] + V[\"C2\"];\n",
    "\n",
    "    V[\"ssim_1\"] = V[\"ssim_t1\"] / V[\"ssim_b1\"];\n",
    "    V[\"ssim_2\"] = V[\"ssim_t2\"] / V[\"ssim_b2\"];\n",
    "    \n",
    "    # compute the pointwise dSSIM\n",
    "    return V[\"ssim_1\"] * V[\"ssim_2\"];\n",
    "    \"\"\",\n",
    "    type=\"abs\",\n",
    "    eb=1 - dssim_bound,\n",
    "    # 3x3 neighbourhood\n",
    "    neighbourhood=[\n",
    "        # latitude\n",
    "        dict(axis=0, before=1, after=1, boundary=\"valid\"),\n",
    "        # longitude\n",
    "        dict(axis=1, before=1, after=1, boundary=\"valid\"),\n",
    "    ],\n",
    ")\n",
    "qoi_eb_stencil_expr = qoi_eb_stencil._qoi_expr._expr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2d878-b19c-4ac6-950a-a76b359f2804",
   "metadata": {},
   "source": [
    "First, we ensure that the `dssim_mat` function and the dSSIM quantity of interest produce (almost) equivalent results, to ensure that bounding the quantity of interest also bounds the `dssim` score we later showcase.\n",
    "\n",
    "When using the original precision of the data, `float32`, both methods produce the same results, but due to the limited precision some (~0.05%) pointwise dSSIM values are outside the expected range of [-1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77500891-9222-4a09-97f4-a24a61b02631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression_safeguards.utils.bindings import Bindings\n",
    "\n",
    "a1 = ERA5_U.values.astype(np.float32)\n",
    "a2 = ERA5_U_codec[\"zfp.rs\"][eb_abs[0]].values.astype(np.float32)\n",
    "\n",
    "dssim_py = dssim_mat(a1, a2)\n",
    "dssim_qoi = qoi_eb_stencil.evaluate_qoi(\n",
    "    a2,\n",
    "    late_bound=Bindings(\n",
    "        **{\n",
    "            \"$x\": a1,\n",
    "            \"$X\": a1,\n",
    "            \"$x_min\": min(np.nanmin(a1), np.nanmin(a2)),\n",
    "            \"$x_max\": max(np.nanmax(a1), np.nanmax(a2)),\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "\n",
    "assert np.all(dssim_py == dssim_qoi)\n",
    "\n",
    "print(\n",
    "    f\"min(dSSIM)={np.nanmin(dssim_py)} \"\n",
    "    f\"max(dSSIM)={np.nanmax(dssim_py)} \"\n",
    "    f\"mean(dSSIM)={np.nanmean(dssim_py)} \"\n",
    "    f\"outside(dSSIM)={np.mean((dssim_py < 0.0) | (dssim_py > 1.0)) * 100}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180488db-9886-4702-87fe-6a3ab74feb21",
   "metadata": {},
   "source": [
    "When using extended precision, `float64`, the dSSIM values are less often (~0.006%) outside the expected range. Therefore, we use `float64` precision for the data in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1870acc-153e-4563-84ca-79788de9bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = ERA5_U.values.astype(np.float64)\n",
    "a2 = ERA5_U_codec[\"zfp.rs\"][eb_abs[0]].values.astype(np.float64)\n",
    "\n",
    "dssim_py = dssim_mat(a1, a2)\n",
    "dssim_qoi = qoi_eb_stencil.evaluate_qoi(\n",
    "    a2,\n",
    "    late_bound=Bindings(\n",
    "        **{\n",
    "            \"$x\": a1,\n",
    "            \"$X\": a1,\n",
    "            \"$x_min\": min(np.nanmin(a1), np.nanmin(a2)),\n",
    "            \"$x_max\": max(np.nanmax(a1), np.nanmax(a2)),\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "\n",
    "assert np.all(dssim_py == dssim_qoi)\n",
    "\n",
    "print(\n",
    "    f\"min(dSSIM)={np.nanmin(dssim_py)} \"\n",
    "    f\"max(dSSIM)={np.nanmax(dssim_py)} \"\n",
    "    f\"mean(dSSIM)={np.nanmean(dssim_py)} \"\n",
    "    f\"outside(dSSIM)={np.mean((dssim_py < 0.0) | (dssim_py > 1.0)) * 100}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e16da5f-7970-46f0-817d-20926204f236",
   "metadata": {},
   "source": [
    "Since computing the safeguards correction for the dSSIM quantity of interest takes a while, we also use a development reporting API to inject a progress bar into the QoI computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de7392-cac6-415b-a1c3-914757b11803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "from compression_safeguards.safeguards._qois.expr.abc import Expr\n",
    "from compression_safeguards.safeguards._qois.expr.reporter import (\n",
    "    Reporter,\n",
    "    ReportingExpr,\n",
    ")\n",
    "\n",
    "\n",
    "class TqdmReporter(Reporter):\n",
    "    __slots__ = (\"_tqdm\", \"_current\", \"_stack\")\n",
    "    _tqdm: None | tqdm.tqdm\n",
    "    _current: int\n",
    "    _stack: list[int]\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._tqdm = None\n",
    "        self._current = 0\n",
    "        self._stack = []\n",
    "\n",
    "    def enter(self, expr: Expr) -> None:\n",
    "        size = expr.data_expr_size\n",
    "        if self._tqdm is None:\n",
    "            self._tqdm = tqdm.tqdm(\n",
    "                total=size, desc=\"QoI\", postfix=dict(depth=len(self._stack))\n",
    "            )\n",
    "            self._current = 0\n",
    "        self._stack.append(self._current + size)\n",
    "        self._tqdm.set_postfix(refresh=False, depth=len(self._stack))\n",
    "\n",
    "    def exit(self, expr: Expr) -> None:\n",
    "        after = self._stack.pop()\n",
    "        self._tqdm.set_postfix(refresh=False, depth=len(self._stack))\n",
    "        self._tqdm.update(after - self._current)\n",
    "        self._current = after\n",
    "        if len(self._stack) > 0:\n",
    "            return\n",
    "        self._tqdm.close()\n",
    "        self._tqdm = None\n",
    "        self._current = 0\n",
    "\n",
    "\n",
    "reporter = TqdmReporter()\n",
    "qoi_eb_stencil._qoi_expr._expr = qoi_eb_stencil_expr.map_expr(\n",
    "    lambda e: ReportingExpr(e, reporter)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe22bed7-d0e1-41a5-abf8-0a444384f737",
   "metadata": {},
   "source": [
    "Finally, we use the `numcodecs-safeguards` frontend to wrap the safeguards around several different lossy compressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d49ab-d4a1-4cff-b919-814b45e3223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numcodecs_safeguards import SafeguardsCodec\n",
    "from numcodecs_zero import ZeroCodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1821ee0-a767-4cd9-b184-556f8db6c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_U_sg = defaultdict(dict)\n",
    "ERA5_U_sg_cr = defaultdict(dict)\n",
    "\n",
    "for ea in eb_abs:\n",
    "    for codec in [\n",
    "        ZeroCodec(),\n",
    "        Zfp(mode=\"fixed-accuracy\", tolerance=ea),\n",
    "        Sz3(eb_mode=\"abs\", eb_abs=ea),\n",
    "        Sperr(mode=\"pwe\", pwe=ea),\n",
    "    ]:\n",
    "        # Baker et al. recommend one of [0.99, 0.995, 0.99919]\n",
    "        dssim_bound = 0.995\n",
    "\n",
    "        codec_sg = SafeguardsCodec(\n",
    "            codec=codec,\n",
    "            safeguards=[\n",
    "                # guarantee that the global minimum and maximum are preserved,\n",
    "                #  which simplifies the rescaling\n",
    "                dict(kind=\"sign\", offset=\"$x_min\"),\n",
    "                dict(kind=\"sign\", offset=\"$x_max\"),\n",
    "                qoi_eb_stencil,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        ERA5_U_sg_enc = codec_sg.encode(ERA5_U.values)\n",
    "        ERA5_U_sg[codec.codec_id][ea] = ERA5_U.copy(data=codec_sg.decode(ERA5_U_sg_enc))\n",
    "\n",
    "        ERA5_U_sg_cr[codec.codec_id][ea] = (\n",
    "            ERA5_U.nbytes / np.asarray(ERA5_U_sg_enc).nbytes\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feab79be-c338-4d5e-a915-7de77daf8fcd",
   "metadata": {},
   "source": [
    "For comparison, we also check how the SZ3 compressor would perform with a pointwise normalised absolute error (NOA) bound of 1/256, corresponding to the bins that the dSSIM metric first quantizes the data into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1502af9d-024a-4987-b6d4-1e7d31d899ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "noa = Sz3(\n",
    "    eb_mode=\"abs\", eb_abs=(np.nanmax(ERA5_U.values) - np.nanmin(ERA5_U.values)) / 256\n",
    ")\n",
    "ERA5_U_noa_enc = noa.encode(ERA5_U.values)\n",
    "ERA5_U_noa = ERA5_U.copy(data=noa.decode(ERA5_U_noa_enc))\n",
    "ERA5_U_noa_cr = ERA5_U.nbytes / ERA5_U_noa_enc.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283da55b-ce80-40bd-9286-1db480881155",
   "metadata": {},
   "source": [
    "## Visual comparison of the error distributions and dSSIM scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2076435-37d2-444f-ae89-6734209a669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = earthkit.plots.Figure(\n",
    "    size=(10, 15),\n",
    "    rows=4,\n",
    "    columns=2,\n",
    ")\n",
    "\n",
    "plot_u_wind_dssim(ERA5_U, 1.0, fig.add_map(0, 0), \"Original\", span=(-60, 60))\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_codec[\"zfp.rs\"][eb_abs[0]],\n",
    "    ERA5_U_codec_cr[\"zfp.rs\"][eb_abs[0]],\n",
    "    fig.add_map(1, 0),\n",
    "    r\"ZFP($\\epsilon_{{abs}}=1$)\",\n",
    "    span=(0.9, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_codec[\"sz3.rs\"][eb_abs[0]],\n",
    "    ERA5_U_codec_cr[\"sz3.rs\"][eb_abs[0]],\n",
    "    fig.add_map(2, 0),\n",
    "    r\"SZ3($\\epsilon_{{abs}}=1$)\",\n",
    "    span=(0.77, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_codec[\"sperr.rs\"][eb_abs[0]],\n",
    "    ERA5_U_codec_cr[\"sperr.rs\"][eb_abs[0]],\n",
    "    fig.add_map(3, 0),\n",
    "    r\"SPERR($\\epsilon_{{abs}}=1$)\",\n",
    "    span=(0.87, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_noa,\n",
    "    ERA5_U_noa_cr,\n",
    "    fig.add_map(0, 0),\n",
    "    r\"SZ3($\\epsilon_{{noa}}=1/256$)\",\n",
    "    span=(0.999, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_codec[\"zfp.rs\"][eb_abs[1]],\n",
    "    ERA5_U_codec_cr[\"zfp.rs\"][eb_abs[1]],\n",
    "    fig.add_map(1, 1),\n",
    "    r\"ZFP($\\epsilon_{{abs}}=0.1$)\",\n",
    "    span=(0.99, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_codec[\"sz3.rs\"][eb_abs[1]],\n",
    "    ERA5_U_codec_cr[\"sz3.rs\"][eb_abs[1]],\n",
    "    fig.add_map(2, 1),\n",
    "    r\"SZ3($\\epsilon_{{abs}}=0.1$)\",\n",
    "    span=(0.95, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_codec[\"sperr.rs\"][eb_abs[1]],\n",
    "    ERA5_U_codec_cr[\"sperr.rs\"][eb_abs[1]],\n",
    "    fig.add_map(3, 1),\n",
    "    r\"SPERR($\\epsilon_{{abs}}=0.1$)\",\n",
    "    span=(0.97, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "\n",
    "fig.save(\"dssim-codec.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8bf53c-6ee0-4e8a-9edc-79995a080d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = earthkit.plots.Figure(\n",
    "    size=(10, 15),\n",
    "    rows=4,\n",
    "    columns=2,\n",
    ")\n",
    "\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_sg[\"zero\"][eb_abs[0]],\n",
    "    ERA5_U_sg_cr[\"zero\"][eb_abs[0]],\n",
    "    fig.add_map(0, 0),\n",
    "    r\"Safeguards(0, dSSIM)\",\n",
    "    span=(0.999, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_sg[\"zfp.rs\"][eb_abs[0]],\n",
    "    ERA5_U_sg_cr[\"zfp.rs\"][eb_abs[0]],\n",
    "    fig.add_map(1, 0),\n",
    "    r\"Safeguards(ZFP($\\epsilon_{{abs}}=1$), dSSIM)\",\n",
    "    span=(0.999, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_sg[\"sz3.rs\"][eb_abs[0]],\n",
    "    ERA5_U_sg_cr[\"sz3.rs\"][eb_abs[0]],\n",
    "    fig.add_map(2, 0),\n",
    "    r\"Safeguards(SZ3($\\epsilon_{{abs}}=1$), dSSIM)\",\n",
    "    span=(0.999, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_sg[\"sperr.rs\"][eb_abs[0]],\n",
    "    ERA5_U_sg_cr[\"sperr.rs\"][eb_abs[0]],\n",
    "    fig.add_map(3, 0),\n",
    "    r\"Safeguards(SPERR($\\epsilon_{{abs}}=1$), dSSIM)\",\n",
    "    span=(0.999, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_sg[\"zfp.rs\"][eb_abs[1]],\n",
    "    ERA5_U_sg_cr[\"zfp.rs\"][eb_abs[1]],\n",
    "    fig.add_map(1, 1),\n",
    "    r\"Safeguards(ZFP($\\epsilon_{{abs}}=0.1$), dSSIM)\",\n",
    "    span=(0.999, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_sg[\"sz3.rs\"][eb_abs[1]],\n",
    "    ERA5_U_sg_cr[\"sz3.rs\"][eb_abs[1]],\n",
    "    fig.add_map(2, 1),\n",
    "    r\"Safeguards(SZ3($\\epsilon_{{abs}}=0.1$), dSSIM)\",\n",
    "    span=(0.999, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "plot_u_wind_dssim(\n",
    "    ERA5_U_sg[\"sperr.rs\"][eb_abs[1]],\n",
    "    ERA5_U_sg_cr[\"sperr.rs\"][eb_abs[1]],\n",
    "    fig.add_map(3, 1),\n",
    "    r\"Safeguards(SPERR($\\epsilon_{{abs}}=0.1$), dSSIM)\",\n",
    "    span=(0.999, 1.0),\n",
    "    error=True,\n",
    ")\n",
    "\n",
    "fig.save(\"dssim-sg.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b15f6-b44c-416a-925e-84058288bfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
